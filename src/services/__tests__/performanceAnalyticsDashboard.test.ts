import { describe, it, expect, vi, beforeEach, afterEach } from "vitest";
import {
  performanceAnalyticsDashboard,
  type PerformanceAlert,
  type PerformanceMetrics,
  type ABTest,
  type ABTestVariant,
} from "../performanceAnalyticsDashboard";

// Mock the dependencies
vi.mock("../mobilePerformanceMonitoring", () => ({
  mobilePerformanceMonitoring: {
    onPerformanceReport: vi.fn(),
    getCurrentPerformanceSnapshot: vi.fn(() => ({
      id: "perf-report-1",
      timestamp: new Date(),
      deviceInfo: {
        isMobile: true,
        userAgent:
          "Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15",
        viewport: { width: 375, height: 667 },
      },
      coreWebVitals: {
        lcp: 2000,
        fid: 100,
        cls: 0.1,
        fcp: 1500,
        tti: 2500,
        tbt: 200,
      },
      memoryMetrics: {
        usedJSHeapSize: 25000000,
        totalJSHeapSize: 50000000,
        jsHeapSizeLimit: 100000000,
        memoryPressure: "low" as const,
      },
      networkMetrics: {
        connectionType: "4g",
        effectiveType: "4g",
        downlink: 10,
        rtt: 100,
        saveData: false,
      },
      pageUrl: "https://example.com",
      sessionId: "session-123",
    })),
    checkPerformanceThresholds: vi.fn(() => ({ hasIssues: false, issues: [] })),
  },
}));

vi.mock("../mobileErrorTracking", () => ({
  mobileErrorTracking: {
    onErrorReport: vi.fn(),
    getSessionErrors: vi.fn(() => []),
  },
}));

describe("PerformanceAnalyticsDashboardService", () => {
  let mockAlertCallback: any;
  let mockMetricsCallback: any;

  beforeEach(() => {
    vi.clearAllMocks();
    mockAlertCallback = vi.fn();
    mockMetricsCallback = vi.fn();

    // Clear any existing state
    performanceAnalyticsDashboard.stopMonitoring();
  });

  afterEach(() => {
    performanceAnalyticsDashboard.stopMonitoring();
  });

  describe("Monitoring", () => {
    it("should start and stop monitoring", () => {
      expect(() => {
        performanceAnalyticsDashboard.startMonitoring();
        performanceAnalyticsDashboard.stopMonitoring();
      }).not.toThrow();
    });

    it("should collect current metrics", () => {
      performanceAnalyticsDashboard.startMonitoring();

      const metrics = performanceAnalyticsDashboard.getCurrentMetrics();

      expect(metrics).toMatchObject({
        timestamp: expect.any(Date),
        coreWebVitals: {
          lcp: {
            value: expect.any(Number),
            grade: expect.stringMatching(/^(good|needs-improvement|poor)$/),
          },
          fid: {
            value: expect.any(Number),
            grade: expect.stringMatching(/^(good|needs-improvement|poor)$/),
          },
          cls: {
            value: expect.any(Number),
            grade: expect.stringMatching(/^(good|needs-improvement|poor)$/),
          },
        },
        memoryUsage: {
          current: expect.any(Number),
          peak: expect.any(Number),
          pressure: expect.stringMatching(/^(low|medium|high|critical)$/),
        },
        errorRate: {
          total: expect.any(Number),
          rate: expect.any(Number),
          criticalErrors: expect.any(Number),
        },
        networkPerformance: {
          connectionType: expect.any(String),
          effectiveType: expect.any(String),
          downlink: expect.any(Number),
          rtt: expect.any(Number),
        },
        deviceInfo: {
          isMobile: expect.any(Boolean),
          platform: expect.any(String),
          browserName: expect.any(String),
          viewportSize: expect.objectContaining({
            width: expect.any(Number),
            height: expect.any(Number),
          }),
        },
      });
    });

    it("should get metrics history for date range", () => {
      performanceAnalyticsDashboard.startMonitoring();

      const startDate = new Date(Date.now() - 24 * 60 * 60 * 1000); // 24 hours ago
      const endDate = new Date();

      const history = performanceAnalyticsDashboard.getMetricsHistory(
        startDate,
        endDate
      );

      expect(Array.isArray(history)).toBe(true);
      history.forEach((metric) => {
        expect(metric.timestamp).toBeInstanceOf(Date);
        expect(metric.timestamp.getTime()).toBeGreaterThanOrEqual(
          startDate.getTime()
        );
        expect(metric.timestamp.getTime()).toBeLessThanOrEqual(
          endDate.getTime()
        );
      });
    });
  });

  describe("Alerts", () => {
    it("should create and manage alerts", () => {
      const unsubscribe =
        performanceAnalyticsDashboard.onAlert(mockAlertCallback);

      performanceAnalyticsDashboard.startMonitoring();

      // Initially should have no active alerts
      expect(performanceAnalyticsDashboard.getActiveAlerts()).toHaveLength(0);

      unsubscribe();
    });

    it("should acknowledge alerts", () => {
      performanceAnalyticsDashboard.startMonitoring();

      // Create a mock alert by updating config to trigger alerts
      performanceAnalyticsDashboard.updateConfig({
        alertThresholds: {
          lcp: { warning: 1000, critical: 1500 }, // Very low thresholds to trigger alerts
          fid: { warning: 50, critical: 100 },
          cls: { warning: 0.05, critical: 0.1 },
          memoryUsage: {
            warning: 10 * 1024 * 1024,
            critical: 20 * 1024 * 1024,
          },
          errorRate: { warning: 1, critical: 2 },
        },
      });

      // Wait a bit for metrics collection
      return new Promise<void>((resolve) => {
        setTimeout(() => {
          const alerts = performanceAnalyticsDashboard.getAllAlerts();

          if (alerts.length > 0) {
            const alertId = alerts[0].id;
            const acknowledged =
              performanceAnalyticsDashboard.acknowledgeAlert(alertId);
            expect(acknowledged).toBe(true);

            const updatedAlert = performanceAnalyticsDashboard
              .getAllAlerts()
              .find((a) => a.id === alertId);
            expect(updatedAlert?.acknowledged).toBe(true);
          }

          resolve();
        }, 100);
      });
    });

    it("should resolve alerts", () => {
      performanceAnalyticsDashboard.startMonitoring();

      // Create a mock alert by updating config to trigger alerts
      performanceAnalyticsDashboard.updateConfig({
        alertThresholds: {
          lcp: { warning: 1000, critical: 1500 },
          fid: { warning: 50, critical: 100 },
          cls: { warning: 0.05, critical: 0.1 },
          memoryUsage: {
            warning: 10 * 1024 * 1024,
            critical: 20 * 1024 * 1024,
          },
          errorRate: { warning: 1, critical: 2 },
        },
      });

      return new Promise<void>((resolve) => {
        setTimeout(() => {
          const alerts = performanceAnalyticsDashboard.getAllAlerts();

          if (alerts.length > 0) {
            const alertId = alerts[0].id;
            const resolved =
              performanceAnalyticsDashboard.resolveAlert(alertId);
            expect(resolved).toBe(true);

            const updatedAlert = performanceAnalyticsDashboard
              .getAllAlerts()
              .find((a) => a.id === alertId);
            expect(updatedAlert?.resolvedAt).toBeInstanceOf(Date);
            expect(updatedAlert?.acknowledged).toBe(true);
          }

          resolve();
        }, 100);
      });
    });
  });

  describe("A/B Testing", () => {
    it("should create A/B tests", () => {
      const testId = performanceAnalyticsDashboard.createABTest({
        name: "Mobile Performance Test",
        description: "Testing mobile performance optimizations",
        startDate: new Date(),
        variants: [
          {
            id: "control",
            name: "Control",
            description: "Original version",
            enabled: true,
            trafficPercentage: 50,
            config: {},
            metrics: {
              participants: 0,
              conversions: 0,
              conversionRate: 0,
              avgPerformanceScore: 0,
              errorRate: 0,
            },
          },
          {
            id: "optimized",
            name: "Optimized",
            description: "Performance optimized version",
            enabled: true,
            trafficPercentage: 50,
            config: { enableOptimizations: true },
            metrics: {
              participants: 0,
              conversions: 0,
              conversionRate: 0,
              avgPerformanceScore: 0,
              errorRate: 0,
            },
          },
        ],
        targetMetric: "performance",
      });

      expect(testId).toMatch(/^test_/);

      const test = performanceAnalyticsDashboard.getABTestResults(testId);
      expect(test).toMatchObject({
        id: testId,
        name: "Mobile Performance Test",
        status: "draft",
        variants: expect.arrayContaining([
          expect.objectContaining({ id: "control", name: "Control" }),
          expect.objectContaining({ id: "optimized", name: "Optimized" }),
        ]),
      });
    });

    it("should start and stop A/B tests", () => {
      const testId = performanceAnalyticsDashboard.createABTest({
        name: "Test A/B Test",
        description: "Test description",
        startDate: new Date(),
        variants: [
          {
            id: "variant-a",
            name: "Variant A",
            description: "First variant",
            enabled: true,
            trafficPercentage: 100,
            config: {},
            metrics: {
              participants: 0,
              conversions: 0,
              conversionRate: 0,
              avgPerformanceScore: 0,
              errorRate: 0,
            },
          },
        ],
        targetMetric: "performance",
      });

      // Start the test
      const started = performanceAnalyticsDashboard.startABTest(testId);
      expect(started).toBe(true);

      let test = performanceAnalyticsDashboard.getABTestResults(testId);
      expect(test?.status).toBe("running");

      // Stop the test
      const stopped = performanceAnalyticsDashboard.stopABTest(testId);
      expect(stopped).toBe(true);

      test = performanceAnalyticsDashboard.getABTestResults(testId);
      expect(test?.status).toBe("completed");
      expect(test?.endDate).toBeInstanceOf(Date);
    });

    it("should assign variants to users", () => {
      const testId = performanceAnalyticsDashboard.createABTest({
        name: "User Assignment Test",
        description: "Testing user assignment",
        startDate: new Date(),
        variants: [
          {
            id: "variant-1",
            name: "Variant 1",
            description: "First variant",
            enabled: true,
            trafficPercentage: 50,
            config: {},
            metrics: {
              participants: 0,
              conversions: 0,
              conversionRate: 0,
              avgPerformanceScore: 0,
              errorRate: 0,
            },
          },
          {
            id: "variant-2",
            name: "Variant 2",
            description: "Second variant",
            enabled: true,
            trafficPercentage: 50,
            config: {},
            metrics: {
              participants: 0,
              conversions: 0,
              conversionRate: 0,
              avgPerformanceScore: 0,
              errorRate: 0,
            },
          },
        ],
        targetMetric: "performance",
      });

      performanceAnalyticsDashboard.startABTest(testId);

      // Test user assignment
      const userId1 = "user-123";
      const userId2 = "user-456";

      const variant1 = performanceAnalyticsDashboard.getVariantForUser(
        testId,
        userId1
      );
      const variant2 = performanceAnalyticsDashboard.getVariantForUser(
        testId,
        userId2
      );

      expect(variant1).toBeDefined();
      expect(variant2).toBeDefined();

      // Same user should get same variant
      const variant1Again = performanceAnalyticsDashboard.getVariantForUser(
        testId,
        userId1
      );
      expect(variant1Again?.id).toBe(variant1?.id);
    });

    it("should record conversions", () => {
      const testId = performanceAnalyticsDashboard.createABTest({
        name: "Conversion Test",
        description: "Testing conversions",
        startDate: new Date(),
        variants: [
          {
            id: "conversion-variant",
            name: "Conversion Variant",
            description: "Variant for conversion testing",
            enabled: true,
            trafficPercentage: 100,
            config: {},
            metrics: {
              participants: 0,
              conversions: 0,
              conversionRate: 0,
              avgPerformanceScore: 0,
              errorRate: 0,
            },
          },
        ],
        targetMetric: "conversion",
      });

      performanceAnalyticsDashboard.startABTest(testId);

      const userId = "conversion-user-123";

      // Assign user to variant
      const variant = performanceAnalyticsDashboard.getVariantForUser(
        testId,
        userId
      );
      expect(variant).toBeDefined();
      expect(variant?.metrics.participants).toBe(1);

      // Record conversion
      performanceAnalyticsDashboard.recordConversion(testId, userId);

      const updatedTest =
        performanceAnalyticsDashboard.getABTestResults(testId);
      const updatedVariant = updatedTest?.variants.find(
        (v) => v.id === "conversion-variant"
      );

      expect(updatedVariant?.metrics.conversions).toBe(1);
      expect(updatedVariant?.metrics.conversionRate).toBe(100); // 1/1 * 100
    });
  });

  describe("Configuration", () => {
    it("should update configuration", () => {
      const newConfig = {
        refreshInterval: 60000,
        enableRealTimeAlerts: false,
        alertThresholds: {
          lcp: { warning: 3000, critical: 5000 },
          fid: { warning: 150, critical: 400 },
          cls: { warning: 0.15, critical: 0.3 },
          memoryUsage: {
            warning: 75 * 1024 * 1024,
            critical: 150 * 1024 * 1024,
          },
          errorRate: { warning: 8, critical: 15 },
        },
      };

      expect(() => {
        performanceAnalyticsDashboard.updateConfig(newConfig);
      }).not.toThrow();
    });

    it("should export dashboard data", () => {
      performanceAnalyticsDashboard.startMonitoring();

      const exportedData = performanceAnalyticsDashboard.exportData();

      expect(exportedData).toMatchObject({
        metrics: expect.any(Array),
        alerts: expect.any(Array),
        abTests: expect.any(Array),
        config: expect.objectContaining({
          refreshInterval: expect.any(Number),
          alertThresholds: expect.any(Object),
          retentionPeriod: expect.any(Number),
          enableRealTimeAlerts: expect.any(Boolean),
        }),
      });
    });

    it("should cleanup old data", () => {
      expect(() => {
        performanceAnalyticsDashboard.cleanupOldData();
      }).not.toThrow();
    });
  });

  describe("Callbacks", () => {
    it("should register and unregister alert callbacks", () => {
      const callback = vi.fn();
      const unsubscribe = performanceAnalyticsDashboard.onAlert(callback);

      expect(typeof unsubscribe).toBe("function");
      expect(() => unsubscribe()).not.toThrow();
    });

    it("should register and unregister metrics callbacks", () => {
      const callback = vi.fn();
      const unsubscribe =
        performanceAnalyticsDashboard.onMetricsUpdate(callback);

      expect(typeof unsubscribe).toBe("function");
      expect(() => unsubscribe()).not.toThrow();
    });
  });
});
